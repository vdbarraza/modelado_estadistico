---
title: "Trabajo Práctico N° 3"
author: "Barraza, Veronica y Maldonado, Kevin"
date: "Julio 2022"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    df_print: paged
geometry: margin=2cm
header-includes:
- \renewcommand\figurename{Figura}
fontsize: 10pt
spacing: double
lang: es-ARG
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

if (!require("tidyverse")) install.packages("tidyverse")
if (!require("MASS")) install.packages("MASS")
if (!require("betareg")) install.packages("betareg")
if (!require("effects")) install.packages("effects")
if (!require("ggpubr")) install.packages("ggpubr")
if (!require("tm")) install.packages("tm")
if (!require("caret")) install.packages("caret")


library(dplyr)
library(MASS)
library(ggplot2)
library(purrr)
library(betareg)
library(nnet)
library(effects)
library(ggpubr)
library(tm)
library(mgcv)
```

### Planteo del problema

En este trabajo práctico se utilizará un dataset que contiene 4000 títulos de una plataforma de streaming. El archivo credits train contiene los actores y directores para estas peíıculas y series. El objetivo de
trabajo es  predecir la calificación de IMDB a partir de otras covariables para cada título.
En este trabajo, se va a considerar la pérdida cuadrática como forma de evaluar
modelos.


### Análisis exploratorio de datos (EDA)

En esta sección vamos a realizar una exploración del dataset. 
(a) ¿Hay algún género que parezca estar más asociado con el puntaje del título?
(b) ¿Cómo fue evolucionando este puntaje a lo largo del tiempo?
(c) ¿Hay algún actor o director asociado con mayores o menores puntajes?
(d) ¿Las películas más populares son las mejor puntuadas?

Antes de comenzar el análisis de EDA, tenemos que realizar una limpieza del dataset. Para esto eliminamos valores nulos, duplicados y dos columnas que presentaban un porcentaje muy alto de valores nuelos. Asimismo, veremos que el dataset contiene información de peliculas y series, pero nos quedaremos solamente con los datos relacionados a las peliculas.

```{r}
options(warn = -1)
credit <- readr::read_csv("credits_train.csv") 
title <- readr::read_csv("titles_train.csv") 

colSums(is.na(title)) # check number of missing value of each columns

#eliminar duplicados
title = title %>% group_by(imdb_id) %>% filter(row_number() == 1)

# elimine las columnas con muchos null
title <- subset(title, select = -c(seasons,age_certification )) #drop "Poster Link" & "Overview" columns
head(title)
colSums(is.na(title)) #chek number of missing value of each columns

title <- title[-which(is.na(title$imdb_votes)),]

colSums(is.na(title)) #check if there's still any missing value

```


```{r fig.cap=" N° de observaciones con información de peliculas y series", out.width="80%", fig.align="center"}
#(1)
type_movie <- title %>% filter(type=='MOVIE')
type_tv <- title %>% filter(type=='SHOW')
ggplot() + geom_bar(title, mapping = aes(type)) #plot the different type of the movie
```


Ahora podemos visualizar como es la distribución de la variable de interes imdb_score.

```{r fig.cap=" Distribución de IMDB_SCORE", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
title %>% ggplot(aes(x=imdb_score, y=..density..)) + geom_histogram()
```

A continuación se muestra la distribución del score en función de los distintos géneros considerando tanto las películas como las series. A nivel general se observa que la mediana se encuentra cercana a 7, con rangos dinámicos que varian entre 3 a 8. Las peliculas de horror presentan una mediana menor de 6. 

```{r fig.cap=" Boxplot: distribución del score en función de los distintos géneros", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
allGenres = c()
allGenresScores = c()
for (rowIdx in 1:nrow(title)) {
  genresChr = title[[rowIdx, "genres"]]
  rowGenders = str_match_all(genresChr, regex("[a-z]+"))[[1]][, 1]
  if (length(rowGenders) > 0) {
    for (genreIdx in 1:length(rowGenders)) {
      allGenres = c(allGenres, rowGenders[genreIdx])
      allGenresScores = c(allGenresScores, title[[rowIdx, "imdb_score"]])
    }
  }
}
tibble(genre=allGenres, score=allGenresScores) %>%
  mutate(genre = factor(genre)) %>% 
  ggplot(aes(y=genre, x=score)) + geom_boxplot()

```

Finalmente, cuando relacionamos los score en función del año de estreno y considerando el tipo, vemos que habrían diferencias en cuanto a su relación con el score.En general, podemos osbervar que las series presentan valores de score rating mayores y que para ambos tipos disminuye con el año.

```{r fig.cap=" IMDB_score versus año de estreno, en función del tipo (películas o serie)", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
title %>%
  ggplot(aes(x=release_year, y=imdb_score, colour=type)) +
  geom_point(alpha=0.3) +
  geom_smooth(method = "lm")

```



```{r  fig.cap=" Distribución de IMDB_SCORE para cada tipo (película o serie)", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
title %>% ggplot(aes(x=type, y=imdb_score)) +
  geom_violin() + geom_boxplot(width=0.1)
```


Ahora podemos visualizar como es la distribución de la variable de interes imdb_score solamente para las observaciones relacionadas a las peliculas.

```{r}
title<- title[title$type=='MOVIE',]
```


```{r fig.cap=" Distribución de IMDB_SCORE para las películas", out.width="80%", fig.align="center", fig.width=5, fig.height=3}

ggplot(title, aes(x=imdb_score)) +
  geom_histogram(fill="lightgreen", alpha = 0.7)+
  theme_bw()+
  labs(x = "Imdb rating", y= "Count", title = "Distribution of Imdb rating by movie")

```

En la siguiente figura se observa la relación entre el score y el número de votantes. Del mismo, podemos ver que para los score mayores hay mayor número de votantes, y aumenta la dispersión del score para valores bajos de votantes.

```{r  fig.cap="Relación entre IMDB score verus n°votantes ", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
 ggplot(title, aes(x=imdb_votes, y = imdb_score))+
  geom_point(colour = "blue", alpha = 0.5)+
  theme_bw()+
  geom_smooth()+
  labs(x = "Number votes", y= "Imdb score")+ 
  theme(axis.text.x=element_text(angle=90, hjust = 1, vjust = 0))+
  theme(legend.position="none")
```

A continuación podemos ver las 5 películas que poseen el score más alto.

```{r}
top5_rating <- title[order(title$imdb_score,decreasing = T),][1:5,]
top5_rating
```

```{r fig.cap=" Top 5 peliculas basadas según el IMDB_SCORE", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
ggplot(top5_rating, aes(x = imdb_score,y = reorder(title, imdb_score))) +
  geom_col(aes(fill =imdb_score), show.legend = F) +
  labs(title = "Top 5 Movies based on IMDB Rating",
       x = "IMDB Rating",
       y = NULL) +
  geom_label(aes(label = imdb_score), hjust = 1.05) +
  scale_fill_gradient(low = "red", high = "black") +
  theme_minimal()
```

Antes de analizar la relación entre el género de las películas y el score, vamos a visualizar la frecuencia de los géneros para este dataset.Los géneros más frecuentes son : drama, comedia, acción, romance y thriller. En el próximo gráfico, podemos ver los box-plot de los scores para los géneros más frecuentes. En general se observa que no parecerían haber una relación entre los score y los géneros. Los géneros de documentales y crimen presentan una mediana mayor al resto y con un menor rango dinámico.

```{r fig.cap=" Frecuencia de peliculas con los diez generos más relevantes", out.width="80%", fig.align="center", fig.width=5, fig.height=3}

# TODO: Replace Genre with a collection of binary columns
genreCorpus = VCorpus(VectorSource(title$genres))
genreCorpus = tm_map(genreCorpus, content_transformer(tolower))
genreCorpus = tm_map(genreCorpus, removeWords, c("N/A"))
genreCorpus = tm_map(genreCorpus, removePunctuation)
genreDocumentTermMatrix = DocumentTermMatrix(genreCorpus)
genreMatrix = as.data.frame(as.matrix(genreDocumentTermMatrix))
title = merge(genreMatrix, title, by=0, all=TRUE)

# TODO: Select movies from top 10 most common genres and plot their relative proportions
genreFrequencies = colSums(as.matrix(genreDocumentTermMatrix))
genreFrequenciesOrdered = genreFrequencies[order(genreFrequencies,decreasing = TRUE)]
topGenres = genreFrequenciesOrdered[1:10]
topGenresName = names(topGenres)
genresDataFrame = data.frame(names(genreFrequenciesOrdered),
                             genreFrequenciesOrdered/sum(genreFrequencies))
names(genresDataFrame) = c("Genre","Frequency")
chart <- ggplot(genresDataFrame) + geom_bar(aes(x = Genre, y = Frequency), stat = "identity") + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + ggtitle(" Movies Genre frequency")
print(chart)
```
`boxplot(Action$rating, Animation$rating, Comedy$rating, Drama$rating, Documentary$rating, Romance$rating, Short$rating, names = c("Action", "Animation", "Comedy", "Drama", "Documentary", "Romance", "Short"), main = "Ratings by Genre", ylab = "Rating")



```{r fig.cap=" Boxplot de IMDB_SCORE en función de los generos más relevantes", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
boxplot(title$imdb_score[title$action==1],
        title$imdb_score[title$animation==1],
        title$imdb_score[title$comedy==1],
        title$imdb_score[title$drama==1],
        title$imdb_score[title$documentation==1],
        title$imdb_score[title$romance==1],
        title$imdb_score[title$crime==1],
        names = c("Action", "Animation", "Comedy", "Drama", "Documentary", "Romance", "Crime"),
        main = "Ratings by Genre",
        ylab = "Rating")

```

En la siguiente gráfica podemos observar el score promedio para los países que produjeron las películas con mayor score.

```{r fig.cap=" Promedio de IMDB_SCORE en función de los países", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
title$production_countries <-factor(title$production_countries)
movies<-title
#Top 10 countries by average IMDB rating per movie
movies %>%
  group_by(production_countries) %>%
  summarise(num = n_distinct(title),
            average_rating = mean(imdb_score,na.rm = "true")) %>%
  arrange(-average_rating) %>%
  head(10) %>%
  ggplot(aes(reorder(production_countries,average_rating),average_rating,fill=production_countries))+
  #ggplot(aes(reorder(country,-num),num),fill=country)+
  geom_bar(stat = "identity")+
  theme(axis.text.x = element_text(angle=90),plot.title=element_text(color="Black",face="bold"),legend.position="none")+
  xlab("")+ylab("Average IMDB rating")+
  ggtitle("Top countries by average IMDB rating of movies")
```

Finalmente, en esta última figura podemos ver la distribución de los score en función de los actores/directores de las misma. De la misma es posible observar que los actores/directores varian en función del rango dinámico, pero en general la mediana se encuentra cercana a 8.

```{r fig.cap=" Boxplot de IMDB_SCORE de actores/directores", out.width="80%", fig.align="center", fig.width=5, fig.height=3}
movie <- merge(title, credit, by = 'id')
lead_actor_table = movie %>% group_by(name) %>% 
  summarise(mean_imdb = mean(imdb_score, na.rm=T), 
            total_movies = n(), 
            standard_dev = sd(imdb_score), 
            lower_bound = mean_imdb- 2* standard_dev/sqrt(total_movies), 
            upper_bound = mean_imdb+ 2* standard_dev/sqrt(total_movies) ) %>% 
  arrange(desc(mean_imdb))


lead_actor_table = subset(lead_actor_table, lead_actor_table$name != "")

actor_mean_movies = mean(lead_actor_table$total_movies)

lead_actor_table = lead_actor_table %>% filter(total_movies >= 3)

top_30_actors = lead_actor_table %>% slice(1:30)

top_30_actors$actor_1_name = factor(top_30_actors$name, levels = top_30_actors$actor_1_name[order(top_30_actors$mean_imdb)])

ggplot(top_30_actors, aes(x = mean_imdb, xmin = lower_bound, xmax = upper_bound, y = name)) +
  geom_point() + 
  geom_segment( aes(x = lower_bound, xend = upper_bound, y = name, yend=name)) + 
  theme(axis.text=element_text(size=8)) + 
  xlab("Mean Movie Rating") + ylab("Lead Actor") + 
  ggtitle("Best Actors/directos by IMDB Movie Rating") + theme_bw()
```
### Modelos lineales mixtos

Los modelos lineales mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relación entre el vector de observaciones  $Y_i$ del sujeto o grupo  $i$ y las covariables.

La forma general de un modelo lineal mixto es:

$Y = Xb + Zu + e$

donde: $Y$ es el vector de respuesta (datos), $X$ y $Z$ son matrices de diseño conocidas, b es un vector de parámetros fijos, u (efectos aleatorios) y e (error) son vectores aleatorios no observables. Las esperanzas matemáticas de u y e, se asumen igual a cero.

2) A continucación vamos a implementar estos modelos en el marco del objetivo de este trabajo práctico: estimar el IMDB score de las peliculas.

a) Plantear un modelo de efectos fijos para predecir el puntaje de IMDB únicamente en función
del país de origen.

- Modelo lineal sin intercept con un efecto fijo por país

Antes de poder fitear el modelo, vamos a separar los paises presentes en la variable prdoction countris, para poder analizar correctamente el efecto del mismo en la estimación del score.

```{r}
allCountries = c()
allCountriesScores = c()
releaseYears = c()
for (rowIdx in 1:nrow(title)) {
  countriesChr = title[[rowIdx, "production_countries"]]
  rowCountries = str_match_all(countriesChr, regex("[A-Z]+"))[[1]][, 1]
  if (length(rowCountries) > 0) {
    for (countryIdx in 1:length(rowCountries)) {
      allCountries = c(allCountries, rowCountries[countryIdx])
      allCountriesScores = c(allCountriesScores, title[[rowIdx, "imdb_score"]])
      releaseYears = c(releaseYears, title[[rowIdx, "release_year"]])
      
    }
  }
}

countriesScoresDf = tibble(country=allCountries,
                           score=allCountriesScores,
                           releaseYear=releaseYears)
topCountries = (countriesScoresDf 
                %>% group_by(country) 
                %>% summarise(meanScore = median(score)) 
                %>% arrange(desc(meanScore)))[["country"]][1:10]
countriesScoresDf %>%
  filter(country %in% topCountries) %>% 
  mutate(country = factor(country)) %>% 
  ggplot(aes(y=reorder(country, score), x=score)) + geom_boxplot()

```


```{r}
# Modelo lineal sin intercept con un efecto fijo por país
fit_1 = lm(score ~ country - 1, data = countriesScoresDf)

fit_1 %>% summary()
```

b) Plantear un modelo de efectos aleatorios para predecir el puntaje de IMDB únicamente en
función del país de origen

-  Modelo mixto con intercept fijo y un efecto aleatorio por país
```{r}
library(lme4)
# Modelo mixto con intercept fijo + un efecto aleatorio por county
fit_2 = lmer(score ~ (1 | country), data = countriesScoresDf)
fit_2 %>% summary()
```

c) Mostrar las estimaciones de los efectos de ambos modelos en un mismo gráfico e interpretar
cómo se diferencian.

```{r fig.cap=" Comparación entre los valores observados y estimados de cada modelo", out.width="80%"}
library(cowplot)

scoresComparison = tibble(countriesScoresDf)
scoresComparison$fit1Prediction = predict(fit_1, newdata=countriesScoresDf)
scoresComparison$fit2Prediction = predict(fit_2, newdata=countriesScoresDf)

fit_1_plot<- ggplot(scoresComparison, aes(x=score, y=fit1Prediction)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Actual Values', y='Predicted Values', title='Fixed model')

fit_2_plot<- ggplot(scoresComparison, aes(x=score, y=fit2Prediction)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Actual Values', y='Predicted Values', title='Random model')
plot_grid(fit_1_plot, fit_2_plot, labels = "AUTO")
```
```{r}
scoreByCount = tibble(countriesScoresDf) %>%
                  group_by(country) %>%
                  summarise(meanScore=mean(score), count=n())
scoreByCount$fixedEffectPrediction = predict(fit_1, newdata=scoreByCount)
scoreByCount$randomEffectPrediction = predict(fit_2, newdata=scoreByCount)

randomEffectIntercept = fixef(fit_2)[["(Intercept)"]]
scoreByCount %>%
  pivot_longer(c( fixedEffectPrediction, randomEffectPrediction),
               names_to="predictionType",
               values_to = "value") %>% 
  ggplot(aes(x=count, y=value, colour=predictionType)) +
    geom_point(alpha=1/2) + 
    geom_hline(yintercept=randomEffectIntercept,
               linetype="dashed") + 
    ggplot2::annotate(geom="text", x=800, y=randomEffectIntercept+.2, label="Random effects intercept", size=3)

```


3)

a) Usando el modelo de efectos aleatorios del item anterior, decidir, usando la función anova,
si agregar´ıa la variable release year.


```{r}
# Modelo mixto con intercept y pendiente de floor fijas + intercepts y pendientes de floor aleatorios por county
fit_3 = lmer(score ~ releaseYear + (releaseYear | country), data = countriesScoresDf)
fit_3 %>% summary()

# anova para todos los modelos mixtos
anova(fit_2, fit_3, test="Chi")

```

De los resultados observamos que al incorporar en el modelo la variable release year el BIC disminuyo y además resulto estadisticamente significativo. Lo que implica que al incorporar dicha variable se reduzco la varianza del modelo.


(b) Usando el modelo de efectos aleatorios del item anterior, decidir si agregaría la variable
release year separando la data en dos: entrenamiento y testeo (estimar los coeficientes
usando la data de entrenamiento y evualuarlo usando la de testeo).

A partir de ahora vamos a separar nuestro dataset en dos: uno de training o entrenamiento para ajustar el modelo y otro de testeo, para evaluar la performance del mismo.



```{r}
#make this example reproducible
set.seed(1)

#use 70% of dataset as training set and 30% as test set
scoresSample <- sample(c(TRUE, FALSE), nrow(countriesScoresDf), replace=TRUE, prob=c(0.7,0.3))
scores.train  <- countriesScoresDf[scoresSample, ]
scores.test  <- countriesScoresDf[!scoresSample, ]


```

En la siguiente tabla se muestra el RMSE de los dos modelos con y sin Year. Del mismo se observs que se obtuvo un menor RMSE al incorporar el año, y cuando gráficamos la relación 1:1 entre las observaciones y predicciones también podemos ver que el modelo que no incluye el año presenta predicciones de valores constantes para varios valores del score observado. 

```{r tab.cap=" Comparación del RMSE", out.width="80%"}
fit.withoutYear = lmer(score ~ (1 | country), data = scores.train)
fit.withYear =  lmer(score ~ releaseYear + (releaseYear | country), data = scores.train)

scores.test$withoutYearPrediction = predict(fit.withoutYear, newdata=scores.test, allow.new.levels=T)
scores.test$withYearPrediction = predict(fit.withYear, newdata = scores.test, allow.new.levels=T)


fit.comparison = data.frame('modelo'='Sin release_year','RMSE'=sqrt(mean((scores.test$score - scores.test$withoutYearPrediction)^2)))

fit.comparison <- rbind(fit.comparison, data.frame('modelo'='Con release_year','RMSE'=sqrt(mean((scores.test$score - scores.test$withYearPrediction)^2))))

fit.comparison
```

```{r fig.cap=" Comparación entre los valores observados y estimados de cada modelo", out.width="80%"}
# TODO: creo que esto se puede sacar

fit_2_plot<- ggplot(scores.test, aes(x=withoutYearPrediction, y=score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='WithoutYearPrediction')

fit_3_plot<- ggplot(scores.test, aes(x=withYearPrediction, y= score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='With Year Prediction')

plot_grid(fit_2_plot, fit_3_plot, labels = "AUTO")
```


(c) Comparar ambos items anteriores.

Si bien en este caso se llega a la misma conclusión, siempre es conveniente evaluar los modelos utilizando un dataset independiente. De esta forma podremos analizar si el modelo puede generalizar correctamente y estimar la variable de interes usando muestras que no las ha analizado para estimar los parámetros de los modelos.


####  Modelos aditivos generalizados (GAM)


Los GAMs (del inglés generalized additive models) son una generalización de los GLMs para incorporar formas no lineales de los predictores (plines, Polinomios, o funciones Step, etc…). El proceso de suavización en GAMs se lleva a cabo a través de los suavizadores (smoothers), entre los que destacan, entre otros, los Splines penalizados P-Splines.


Al igual que en la sección anterior, vamos a implementar estos modelos para estimar la variable IMDB_score.

a) Usando únicamente la variable release year, predecir la popularidad de cada título (usando un tipo de modelo que crea adecuado) con una curva de splines penalizados. Usar k = 1, 2, 3, 5, 10, 20, 50 nodos y comparar todas las curvas estimadas en un mismo gráfico.

Para cumplir con esta consigna utilizamos ciclos for para fitear cada modelos uzando distintos valores de nodos.

```{r}
#make this example reproducible
set.seed(1)

nodesAmounts = c(1, 2, 3, 5, 10, 20, 50)
pred_gam <-data.frame('imdb_score' = scores.test$score)

for (nodes in nodesAmounts) {
 
  #mod_gam <- gam(imdb_score ~ s(release_year, k = i, sp = 0, bs = 'cr'), data = Train) 
  ## NOTA la libreria anterior me da error
  mod_gam = mgcv::gam(score ~ s(releaseYear, k = nodes, sp = 0, bs = 'cr'), data = scores.train) 
  nam = paste("mod_gam", nodes, sep = "")
  assign(nam, mod_gam)
  preds = predict(mod_gam, scores.test)
  pred_gam = cbind(pred_gam, preds)
  nodesResults =  data.frame('k'= nodes,'rmse'=mean((preds - scores.test$score)^2)) 
  if (nodes == 1) {
    rmse_gam = nodesResults
  } else {
    rmse_gam = rbind(rmse_gam, nodesResults)
  } 
} 

```


Comparemos las predicciones con los distintos modelos:

- Cuando comparamos en la siguiente figura como varía la métrica de RMSE versus k, vemos que el valor más bajo del mismo se obtuvo para un k=5.

```{r fig.cap=" Comparación de RMSE para los modelos en función del valor de k ", out.width="80%"}
ggplot(rmse_gam, aes(x=k, y= rmse)) +
  geom_point() +
  labs(x='k', y='RMSE', title='Gam')
```


Ahora podemos visualirar las estimaciones en un scatter para ver cuanto se alejan de la relación 1:1 entre los valores estimados y predichos. De esta gráfico se observa que ningún modelo parece estimar correctamente el score de las películas, dado que vemos que para distintos valores del score observado se obtiene una predicción que se encuentra entre 6 y 7 del score.

```{r fig.cap=" Comparación entre los valores observados y estimados de cada modelo", out.width="80%"}
## NOTA: no le pude incluir la legenda

# Create Unique Column Names
names(pred_gam) = make.names(names(pred_gam), unique=TRUE)

ggplot(pred_gam, aes(y=imdb_score)) +                    # basic graphical object
  geom_point(aes(x=preds), colour="red") +  # first layer
  geom_point(aes(x=preds.1), colour="green")+  # second layer+
  geom_point(aes(x=preds.2), colour="blue")+  # second layer+ 
  geom_point(aes(x=preds.3), colour="pink")+  # second layer+
  geom_point(aes(x=preds.4), colour="orange")+  # second layer+
  geom_point(aes(x=preds.5), colour="yellow")+  # second layer+
  geom_point(aes(x=preds.6), colour="black")+  # second layer+
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='Modelos GAM diferentes valores de k')
#+    scale_color_manual(values = c("k=1" = "black", "k=2" = "red"))
```

#### Comparación de modelos

En esta sección vamos a implementar una diversidad de modelos y comparar su performance.

a) Dividir al conjunto de datos en entrenamiento y testeo (tambien puede usar otra técnica, como
validación cruzada). Con todas las variables que tiene disponibles, probar al menos 10 modelos
diferentes y elegir el que minimice el error cuadrático médio de predicción para el rating de
IMDB.

Primero vamos a generar un nuevo dataframe con todos los features que podemos utilizar.


```{r}
# TODO: Replace Genre with a collection of binary columns
countryCorpus = VCorpus(VectorSource(as.factor(title$production_countries)))
countryCorpus = tm_map(countryCorpus, content_transformer(tolower))
#removeBracketed <- content_transformer(function(x, ...) {gsub(".*?(\\b[A-Za-z ]+\\b).*","\\1", x)})
#countryCorpus = tm_map(countryCorpus, removeBracketed)
countryCorpus = tm_map(countryCorpus, removePunctuation)
countryDocumentTermMatrix = DocumentTermMatrix(countryCorpus)
countryMatrix = as.data.frame(as.matrix(countryDocumentTermMatrix))
#title = merge(genreMatrix, title, by=0, all=TRUE)
```


```{r}

#make this example reproducible
set.seed(1)

#use 70% of dataset as training set and 30% as test set
scoresSample <- sample(c(TRUE, FALSE), nrow(countriesScoresDf), replace=TRUE, prob=c(0.7,0.3))
Train <- countriesScoresDf[scoresSample, ]
Test  <- countriesScoresDf[!scoresSample, ]

#Features_train<-Train[-c('Row.names','X1','id','title','description','imdb_id','fit_1_score','fit_2_score')]
Features_train<-Train[,3:21] 
Features_train<-cbind(Features_train,Train[,26:27])
Features_train$imdb_score<-Train$imdb_score
#Features_train$runtime<-Train$runtime
Features_train$production_countries<-Train$production_countries
#Features_train$realease_year<-Train$realese_year
#
Features_train$name<-as.factor(Train$name)

Features_test<-Test[,3:21] 
Features_test<-cbind(Features_test,Test[,26:27])
Features_test$imdb_score<-Test$imdb_score
#Features_test$runtime<-Test$runtime
Features_test$production_countries<-Test$production_countries
#Features_test$realease_year<-Test$realese_year
Features_test$name<-as.factor(Test$name)
```


Ahora vamos a seleccionar 10 modelos distintos y compararlos para quedarnos con el que tenga el menor RMSE.Para este punto también vamos a utilizar la librería caret que nos va a permitir tunear los modelos, hacer selección de variables de una forma más simple. Los modelos que vamos a evalurar serán distintas variaciones de los modelos introducidos en las secciones anteriores.

a) Modelos lineales mixtos

```{r}
lmer.all <-lmer(imdb_score ~ 1+crime+documentation+drama+european+family+history+horror+music+romance+scifi+sport+thriller+war+western+(1|release_year)+(1|runtime)+(1|name), data =Features_train) 
lmer.all
```


b) Modelos lineales mixtos

```{r}
lmer.fit2= lmer(imdb_score ~1+crime+documentation+drama+european+family+history+horror+music+romance+scifi+sport+thriller+war+western+ (1 | production_countries)+(1|name), data = Features_train)
lmer.fit2 %>% summary()
```

c) Modelos aditivos utilizando la libreria caret

Para el siguiente modelo, se eliminaron del dataset algunas variables dado por el tiempo que tardaba el modelo en realizar el ajuste de los parámetros (estas variables fueron: nombre, año y país).

```{r}
#make this example reproducible
set.seed(1)
gam.train<-  train(imdb_score ~ . , data=Features_train[,-c(20,23,24)],  method= 'gam',
                family = Gamma(link = log))

gam.train
```

```{r fig.cap=" RMSE selección de variables", out.width="80%"}
trellis.par.set(caretTheme())
plot(gam.train) 
```

d) Modelo GLM bayesiano utilizando la libreria caret

```{r}
 #make this example reproducible
set.seed(1)

bayesglm.train<-  train(imdb_score ~ . , data=Features_train[,-c(20,23,24)],  method= 'bayesglm' ,
                family = Gamma(link = log))

bayesglm.train
```

e) Modelos lineales mixtos en carte utilizando selección de variables

```{r}
#make this example reproducible
set.seed(1)

glm.train<-  train(imdb_score ~ . , data=Features_train[,-c(20,23,24)],   method = 'glmStepAIC',
                family = Gamma(link = log))

glm.train
```


Resultados genrales

```{r}
summary(glm.train)
```


```{r}
lmer_pred <- predict(lmer.all, Features_test, allow.new.levels=T)
resultados<- data.frame('lmer v1'= postResample(pred = lmer_pred, obs = Features_test$imdb_score))
lmer_pred2 <- predict(lmer.fit2, Features_test, allow.new.levels=T)
resultados<- cbind(resultados,'lmer v2'=postResample(pred = lmer_pred2, obs = Features_test$imdb_score))
gam_pred <- predict(gam.train, Features_test[,-c(20,23,24)])
resultados<- cbind(resultados,'gam'=postResample(pred = gam_pred, obs = Features_test$imdb_score))

bh_pred <- predict(bayesglm.train, Features_test[,-c(20,23,24)])
resultados<- cbind(resultados,'bayes'=postResample(pred = bh_pred, obs = Features_test$imdb_score))

gml_pred <- predict(glm.train, Features_test[,-c(20,23,24)])
resultados<- cbind(resultados,'gml'=postResample(pred = gml_pred, obs = Features_test$imdb_score))


Features_test$lmer_pred<-lmer_pred
Features_test$lmer_pred2<-lmer_pred2
Features_test$gam_pred<-gam_pred
Features_test$gml_pred<-gml_pred
Features_test$bh_pred<-bh_pred
resultados

```

```{r}
fit_0_plot<- ggplot(Features_test, aes(x=lmer_pred, y= imdb_score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='lmer v1')
fit_1_plot<- ggplot(Features_test, aes(x=lmer_pred2, y= imdb_score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='lmer v2')

fit_2_plot<- ggplot(Features_test, aes(x=gam_pred, y= imdb_score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='GAM')

fit_3_plot<- ggplot(Features_test, aes(x=gml_pred, y= imdb_score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='GLM')

fit_4_plot<- ggplot(Features_test, aes(x=bh_pred, y= imdb_score)) +
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  labs(x='Predicted Values', y='Actual Values', title='Bayes')


plot_grid(fit_0_plot,fit_1_plot,fit_2_plot, fit_3_plot, fit_4_plot, labels = "AUTO")
```

